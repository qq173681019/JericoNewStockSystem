# 信心度和准确率说明 (Confidence and Accuracy Explanation)

## 信心度 (Confidence)

### 计算方法

信心度是基于三个预测模型的一致性计算得出的：

1. **技术指标预测** (30%权重): MACD, RSI, 移动平均线, 布林带
2. **机器学习预测** (40%权重): Random Forest + 动态特征窗口
3. **支撑阻力位预测** (30%权重): 关键价位识别与趋势分析

#### 计算公式

```python
# 计算三个模型预测的标准差
all_predictions = [tech_prices, ml_prices, sr_prices]
std_dev = np.std(all_predictions, axis=0).mean()
mean_price = np.mean(all_predictions)

# 归一化标准差
normalized_std = std_dev / mean_price

# 信心度计算
confidence = max(0.5, min(0.95, 1 - normalized_std * 10))
```

#### 信心度范围

- **50% - 95%**: 真实预测时的信心度范围
  - 三个模型预测结果越一致，信心度越高
  - 三个模型预测结果差异大时，信心度降低
  
- **30%**: 降级预测（无法获取真实数据时）
  - 显示⚠️警告图标
  - 这表示使用的是模拟数据，不是真实预测

### 为什么30分钟和1天预测都显示30%？

在截图中显示的30%信心度是因为系统无法获取真实的股票数据，使用了降级模式（fallback data）。代码中设置：

```python
confidence = 0.30  # Very low confidence for fallback data
```

当有真实数据时，每个时间框架会根据各自的模型预测一致性独立计算信心度，通常在50%-95%之间。

## 准确率 (Accuracy)

### 当前实现

目前显示的准确率**不是基于历史验证的真实准确率**，而是从信心度派生的估算值：

```python
# 主预测API
accuracy = 78.5 + (confidence - 0.75) * 20

# 降级数据
accuracy = 75.0
```

### 问题

准确率的计算目前**没有依据**，只是一个从信心度派生的数值。真正的准确率应该通过以下方式验证：

1. 保存历史预测记录
2. 与实际价格走势对比
3. 统计预测正确的次数
4. 计算真实准确率 = (正确预测次数 / 总预测次数) × 100%

### 建议

根据issue要求："准确率的评估标准是什么？如果是乱写的请不要添加这个东西"

**建议**: 在实现真实的历史验证系统之前，应该：
- 要么移除准确率显示
- 要么明确标注为"估算值"或"模型信心度"而不是"准确率"

## 中期预测（3个月目标价）

### 确认

中期预测的计算确实是按照3个月的时间框架设计的：

```python
# 代码注释确认
# - 30天预测: 基于日线数据（实际为中期3个月目标）
```

在主预测API中，中期预测使用的是长期趋势分析：

```python
mediumTerm: {
    'targetPrice': round(medium_term_price, 2),
    'timeframe': '3个月',
    'confidence': round(confidence * 0.9, 2)
}
```

### 颜色显示

中期预测现在已经根据与当前价格的对比正确显示颜色：
- 🔴 红色：预测价格高于当前价格（上涨）
- 🟢 绿色：预测价格低于当前价格（下跌）

## 总结

1. ✅ **信心度**: 有明确的计算依据，基于三个模型的预测一致性
2. ❌ **准确率**: 当前没有真实依据，只是从信心度派生的估算值
3. ✅ **中期预测**: 确认是按3个月目标价计算的
4. ✅ **颜色显示**: 已按照中国股市惯例实现（红涨绿跌）

## 建议的改进方向

1. 实现历史预测验证系统，计算真实准确率
2. 在实现真实准确率之前，移除或重新标注当前的"准确率"显示
3. 添加预测结果的跟踪和回测功能
4. 提供准确率的时间维度统计（如：30天准确率、90天准确率等）
